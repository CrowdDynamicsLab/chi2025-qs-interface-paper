\section{Introduction}
Capturing individuals' responses, attitudes, and preferences effectively is the cornerstone of studying human subject studies, especially for the CSCW community. The effectiveness of eliciting these responses hinges upon the study protocol, survey mechanism, and design of the tool at hand~\cite{olsonWaysKnowingHCI2014, couperWebSurveyDesign2001, jackoHumancomputerInteractionHandbook2012}. While much research has explored the influence of the former two aspects, this research focuses on the design of a specific survey -- Quadratic Surveys.

The design in any response-capturing tool significantly influences individuals' ability to express their attitudes. Political scientists have demonstrated that ballot designs alone can sway voter decisions~\cite{engstrom2020politics}, marketing and psychology researchers have examined how the presentation of questions influences responses~\cite{weijtersEffectRatingScale2010, kierujVariationsResponseStyle2010, toepoelSmileysStarsHearts2019}, and Human-Computer Interaction researchers have focused on evaluating and understanding web surveys and smart interfaces for surveys~\cite{farzandAestheticsEvaluatingResponse2024, xiaoTellMeYourself2020, pielotDidYouMisclick2024}. These studies highlight the importance of studying the interface and design for survey mechanisms.

The Quadratic Mechanism is a decision mechanism where individuals express the degree of their preferences within a given budget. Quadratic Voting (QV) leverages this mechanism, allowing participants to allocate a finite amount of credits across a list of options, voting multiple times to demonstrate their strength of approval, as long as the sum of the quadratic values of their votes remains within the given credit~\cite{lalley2018quadratic}. Recent work has demonstrated that QV can gauge public opinions~\cite{quarfoot2017quadratic} and be transformed into Quadratic Surveys (QS) to elicit individual preferences under resource-constrained scenarios~\cite{chengCanShowWhat2021}. These studies suggest that more sophisticated mechanisms can elicit more truthful and carefully identified preferences in complex spaces to inform decision-making.

However, the Quadratic Mechanism is undeniably more complex than other voting and surveying mechanisms, such as the Likert scale~\cite{likertTechniqueMeasurementAttitudes1932}, where individuals select from a few responses, and Approval Voting~\cite{bramsApprovalVoting1978}, where participants mark as many options as they approve without constraints. Responding to a QS involves expressing a numerical representation of a full set of constructed preferences. As Lichtenstein and Slovic~\cite{lichtensteinConstructionPreference2006} pointed out, when individuals do not have clear known preferences, they construct preferences in situ. This can be particularly challenging in unfamiliar contexts, when choices might conflict, and when opinions need to be translated into quantified values. Survey respondents often face these challenges, exacerbated by common constraints and budget allocation, requiring them to make difficult decisions.

This challenge emphasizes the critical importance of designing and developing suitable interfaces for Quadratic Surveys to elicit truthful and in-depth preference information from respondents. Good design is essential; without it, the quality of collected data can suffer significantly. Despite the advocacy of Quadratic Voting by Posner and Weyl~\cite{posner2018radical}, and its experimentation in various contexts such as the Colorado state government, the Democratic Caucus of the House of Representatives~\cite{QuadraticVotingColorado}, government-sponsored hackathons~\cite{teamTaiwanDigitalMinister}, and the recent Gov4git~\cite{Gov4gitDecentralizedPlatform2023}, no peer-reviewed research has focused on the design perspective of such mechanisms. This increasing attention highlights the relevance and potential impact of QS. Additionally, prior research in behavioral economics and marketing has pointed out the challenge of choice overload~\cite{iyengarWhenChoiceDemotivating2000} and overchoice~\cite{gourvilleOverchoiceAssortmentType2005}. While Quadratic Voting allows individuals to allocate resources across multiple options, the presence of many options can overwhelm participants, potentially compromising decision-making quality. It can be difficult for decision-makers to reduce the number of options present in a survey. Effective design may mitigate these overload challenges, ensuring that the Quadratic Survey mechanism fulfills its potential to capture detailed and accurate preferences. These reasons strongly motivate our main research question: \textit{How can we design interactive interfaces to support participants in completing Quadratic Surveys?} Addressing this question fills a important gap in the literature and enhances the practical utility of QS in capturing high-quality data across various applications.

In this study, we aim to reach our goal by answering three research questions:
\begin{itemize}
\item RQ1a. How does the number of options on QS impact respondents' cognitive load?
\item RQ1b. Across the different number of options on QS, what are the sources of cognitive load from?
\item RQ2a. How does the interactive interface involving grouping and direct manipulation interface influence QS respondents' cognitive load compared to text-based interface?
\item RQ2b. Across the two interfaces, what are the sources of cognitive load from?
\item RQ3. What are differences in QS respondents' behaviors when coping with long lists of options?
\end{itemize}

To answer these research questions, we constructed an interactive interface informed by prior literature in questionnaire and survey response format. We iterated the interface after several rounds of pretests and pilots. Then we designed a two-by-two between-subject study where each group of participants would experience a QS with a short or long list of options, using a text-based or interactive-based interface. Study participants' cognitive load was collected using NASA-TLX, a widely used measure, followed by an interview. We recruited 41 participants from a Midwestern local community, asking members to support a wide range of societal issues in an in-lab study.

In the remainder of this paper, we focus on the related works in section~\ref{sec:relatedWorks}. Then we detailed related works that informed the interactive QS interface and the design process in section~\ref{sec:interfaceDesign}. Experiment design follows in section~\ref{sec:experiment}. Study findings and discussion are present in section~\ref{sec:result} and section{sec:discussion}.

\paragraph*{Contributions}
In this study, we highlighted the importance of using a two-step "organize then vote" interactive interface for QS surveys with long lists of options, despite not revealing statistically significant differences in the weighted NASA-TLX scores between the groups. All four groups of participants experienced medium-to-high weighted cognitive load. Our recommendation is based on identified differences in the sources of cognitive load between participants using text-based interfaces and those using interactive interfaces when responding to QS with long lists. Supporting evidence from participants' operating behaviors showed that those using the interactive interface made more rapid and repeated updates when responding to the survey. Conversely, we observed fewer qualitative differences between the groups of participants responding to the short list. This study also provides design recommendations for deploying QS and suggests directions for future research.

